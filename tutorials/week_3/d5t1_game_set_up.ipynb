{"cells":[{"cell_type":"markdown","metadata":{"execution":{},"id":"plRRbfUvLv6g"},"source":["# Tutorial 1: Game Set-Up and Random Player\n","\n","**Week 3, Day 5: Reinforcement Learning for Games**\n","\n","**By Neuromatch Academy**\n","\n","__Content creators:__ Mandana Samiei, Raymond Chua, Tim Lilicrap, Blake Richards\n","\n","__Content reviewers:__ Arush Tagade, Lily Cheng, Melvin Selim Atay, Kelson Shilling-Scrivo\n","\n","__Content editors:__ Melvin Selim Atay, Spiros Chavlis, Gunnar Blohm\n","\n","__Production editors:__ Namrata Bafna, Gagana B, Spiros Chavlis"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"TZ8H8FMQLv6s"},"source":["\n","<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"d1TaKbm2Lv6t"},"source":["---\n","# Tutorial Objectives\n","\n","In this tutorial, you will learn how to implement a game loop and create a random player. In future tutorials, you will be training other types of players using reinforcement learning.\n","\n","The specific objectives for this tutorial:\n","*   Understand the format of two-players games, Othello specifically\n","*   Understand how to create random players\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"ma818bXaLv6v"},"outputs":[],"source":["# @title Tutorial slides\n","\n","from IPython.display import IFrame\n","IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/4p2ek/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"keW1Lqj3Lv6x"},"source":["These are the slides for the videos in the tutorial. If you want to locally download the slides, click [here](https://osf.io/4p2ek/download)."]},{"cell_type":"markdown","metadata":{"execution":{},"id":"j76DyZy4Lv6y"},"source":["---\n","# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"v6nCmsrcLv6z"},"outputs":[],"source":["# @title Install dependencies\n","!pip install coloredlogs --quiet\n","\n","!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n","from evaltools.airtable import AirtableForm\n","\n","# generate airtable form\n","atform = AirtableForm('appn7VdPRseSoMXEG', 'W3D5_T1', 'https://portal.neuromatchacademy.org/api/redirect/to/9c55f6cb-cdf9-4429-ac1c-ec44fe64c303')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"AYgToqYwLv61"},"outputs":[],"source":["# Imports\n","import os\n","import torch\n","import random\n","import logging\n","import coloredlogs\n","import numpy as np\n","import torch.optim as optim\n","\n","log = logging.getLogger(__name__)\n","coloredlogs.install(level='INFO')  # Change this to DEBUG to see more info."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"4H1f4X8fLv63"},"outputs":[],"source":["# @title Set random seed\n","\n","# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n","\n","# For DL its critical to set the random seed so that students can have a\n","# baseline to compare their results to expected results.\n","# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n","\n","# Call `set_seed` function in the exercises to ensure reproducibility.\n","import random\n","import torch\n","\n","def set_seed(seed=None, seed_torch=True):\n","  \"\"\"\n","  Function that controls randomness. NumPy and random modules must be imported.\n","\n","  Args:\n","    seed : Integer\n","      A non-negative integer that defines the random state. Default is `None`.\n","    seed_torch : Boolean\n","      If `True` sets the random seed for pytorch tensors, so pytorch module\n","      must be imported. Default is `True`.\n","\n","  Returns:\n","    Nothing.\n","  \"\"\"\n","  if seed is None:\n","    seed = np.random.choice(2 ** 32)\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  if seed_torch:\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","  print(f'Random seed {seed} has been set.')\n","\n","\n","# In case that `DataLoader` is used\n","def seed_worker(worker_id):\n","  \"\"\"\n","  DataLoader will reseed workers following randomness in\n","  multi-process data loading algorithm.\n","\n","  Args:\n","    worker_id: integer\n","      ID of subprocess to seed. 0 means that\n","      the data will be loaded in the main process\n","      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n","\n","  Returns:\n","    Nothing\n","  \"\"\"\n","  worker_seed = torch.initial_seed() % 2**32\n","  np.random.seed(worker_seed)\n","  random.seed(worker_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"gbL677fYLv6_"},"outputs":[],"source":["# @title Set device (GPU or CPU). Execute `set_device()`\n","# especially if torch modules used.\n","\n","# Inform the user if the notebook uses GPU or CPU.\n","\n","def set_device():\n","  \"\"\"\n","  Set the device. CUDA if available, CPU otherwise\n","\n","  Args:\n","    None\n","\n","  Returns:\n","    Nothing\n","  \"\"\"\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","  if device != \"cuda\":\n","    print(\"WARNING: For this notebook to perform best, \"\n","        \"if possible, in the menu under `Runtime` -> \"\n","        \"`Change runtime type.`  select `GPU` \")\n","  else:\n","    print(\"GPU is enabled in this notebook.\")\n","\n","  return device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"qOBASNfJLv7A"},"outputs":[],"source":["SEED = 2021\n","set_seed(seed=SEED)\n","DEVICE = set_device()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"lo8rlWboLv7A"},"outputs":[],"source":["# @title Download the modules\n","\n","# @markdown Run this cell!\n","\n","# @markdown Download from OSF. The original repo is https://github.com/raymondchua/nma_rl_games.git\n","\n","import os, io, sys, shutil, zipfile\n","from urllib.request import urlopen\n","\n","# download from github repo directly\n","#!git clone git://github.com/raymondchua/nma_rl_games.git --quiet\n","REPO_PATH = 'nma_rl_games'\n","\n","if os.path.exists(REPO_PATH):\n","  download_string = \"Redownloading\"\n","  shutil.rmtree(REPO_PATH)\n","else:\n","  download_string = \"Downloading\"\n","\n","zipurl = 'https://osf.io/kf4p9/download'\n","print(f\"{download_string} and unzipping the file... Please wait.\")\n","with urlopen(zipurl) as zipresp:\n","  with zipfile.ZipFile(io.BytesIO(zipresp.read())) as zfile:\n","    zfile.extractall()\n","print(\"Download completed.\")\n","\n","print(f\"Add the {REPO_PATH} in the path and import the modules.\")\n","# add the repo in the path\n","sys.path.append('nma_rl_games/alpha-zero')\n","\n","# @markdown Import modules designed for use in this notebook\n","import Arena\n","\n","from utils import *\n","from Game import Game\n","from MCTS import MCTS\n","from NeuralNet import NeuralNet\n","\n","# from othello.OthelloPlayers import *\n","from othello.OthelloLogic import Board\n","# from othello.OthelloGame import OthelloGame\n","# from othello.pytorch.NNet import NNetWrapper as NNet"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"d-gseA3dLv7D"},"source":["The hyperparameters used throughout the notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"Zl4sfF3PLv7D"},"outputs":[],"source":["args = dotdict({\n","    'numIters': 1,            # In training, number of iterations = 1000 and num of episodes = 100\n","    'numEps': 1,              # Number of complete self-play games to simulate during a new iteration.\n","    'tempThreshold': 15,      # To control exploration and exploitation\n","    'updateThreshold': 0.6,   # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n","    'maxlenOfQueue': 200,     # Number of game examples to train the neural networks.\n","    'numMCTSSims': 15,        # Number of games moves for MCTS to simulate.\n","    'arenaCompare': 10,       # Number of games to play during arena play to determine if new net will be accepted.\n","    'cpuct': 1,\n","    'maxDepth':5,             # Maximum number of rollouts\n","    'numMCsims': 5,           # Number of monte carlo simulations\n","    'mc_topk': 3,             # Top k actions for monte carlo rollout\n","\n","    'checkpoint': './temp/',\n","    'load_model': False,\n","    'load_folder_file': ('/dev/models/8x100x50','best.pth.tar'),\n","    'numItersForTrainExamplesHistory': 20,\n","\n","    # Define neural network arguments\n","    'lr': 0.001,               # lr: Learning Rate\n","    'dropout': 0.3,\n","    'epochs': 10,\n","    'batch_size': 64,\n","    'device': DEVICE,\n","    'num_channels': 512,\n","})"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"Ee2xj7t5Lv7E"},"source":["---\n","# Section 0: Introduction"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"0cq5U8x2Lv7F"},"outputs":[],"source":["# @title Video 0: Introduction\n","from ipywidgets import widgets\n","\n","out2 = widgets.Output()\n","with out2:\n","  from IPython.display import IFrame\n","  class BiliVideo(IFrame):\n","    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n","      self.id=id\n","      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n","      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n","\n","  video = BiliVideo(id=f\"BV1Yh411B7EP\", width=854, height=480, fs=1)\n","  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n","  display(video)\n","\n","out1 = widgets.Output()\n","with out1:\n","  from IPython.display import YouTubeVideo\n","  video = YouTubeVideo(id=f\"5kQ-xGbjlJo\", width=854, height=480, fs=1, rel=0)\n","  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n","  display(video)\n","\n","out = widgets.Tab([out1, out2])\n","out.set_title(0, 'Youtube')\n","out.set_title(1, 'Bilibili')\n","\n","# add event to airtable\n","atform.add_event('Video 0: Introduction')\n","\n","display(out)"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"kT5g5yadLv7G"},"source":["---\n","# Section 1: Create a game/agent loop for RL\n","\n","*Time estimate: ~20mins*"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"Wi2uK6P7Lv7G"},"outputs":[],"source":["# @title Video 1: A game loop for RL\n","from ipywidgets import widgets\n","\n","out2 = widgets.Output()\n","with out2:\n","  from IPython.display import IFrame\n","  class BiliVideo(IFrame):\n","    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n","      self.id=id\n","      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n","      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n","\n","  video = BiliVideo(id=f\"BV1Wy4y1V7bt\", width=854, height=480, fs=1)\n","  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n","  display(video)\n","\n","out1 = widgets.Output()\n","with out1:\n","  from IPython.display import YouTubeVideo\n","  video = YouTubeVideo(id=f\"aH2Hs8f6KrQ\", width=854, height=480, fs=1, rel=0)\n","  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n","  display(video)\n","\n","out = widgets.Tab([out1, out2])\n","out.set_title(0, 'Youtube')\n","out.set_title(1, 'Bilibili')\n","\n","# add event to airtable\n","atform.add_event('Video 1: A game loop for RL')\n","\n","display(out)"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"Voh7FImULv7H"},"source":["## Section 1.1: Introduction to OthelloGame\n","\n","Othello is a board game played by two players on a board of 64 squares arranged in an eight-by-eight grid, with 64 playing pieces that are black on one side and white on the other. \n","\n","**Setup**:\n","The board will start with 2 black discs and 2 white discs at the centre of the board. They are arranged with black forming a North-East to South-West direction. White is forming a North-West to South-East direction. Each player gets 32 discs and black always starts the game.\n","\n","**Game rules**: \n","* Players take turns placing a single disk at a time. \n","* A move is made by placing a disc of the player's color on the board to surround (i.e. \"outflank\") discs of the opposite color. In other words, the player with black discs must place on so that there is a straight line between the newly placed disc and another black disc, with one or more white pieces between them.\n","* Surrounded disks get flipped (i.e. change color). \n","* If a player does not have a valid move (they cannot place their disc to outflank the oppponent's discs), they pass on their turn\n","* A player can not voluntarily forfeit his turn.\n","* When both players can not make a valid move the game ends.\n","\n","There are nice rules/diagrams here if useful: https://www.eothello.com/. You can play an example Othello game there if you like!\n","\n","**Note**: we will use a 6x6 board to speed computations up"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"ejQNetQ9Lv7I"},"source":["\n","***Exercise Goal***: How to setup a game environment with multiple players for reinforcement learning experiments.\n","\n","***Exercise***: \n","\n","*   Build an agent that plays random moves\n","*   Connect with connect 4 game\n","*   Generate games including wins and losses"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"SjjoyAvkLv7J"},"source":["Execute the following code to enable the `OthelloGame` class. This class represents a game board and has methods such `getInitBoard` to create the intial board, `getValidMove` to return the options of valid moves, and other helpful functionality to play the game. You do not need to understand every line of code in this class but try to get a sense of the possible methods"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"XyskerA-Lv7K"},"outputs":[],"source":["class OthelloGame(Game):\n","  \"\"\"\n","  Instantiate Othello Game\n","  \"\"\"\n","  square_content = {\n","      -1: \"X\",\n","      +0: \"-\",\n","      +1: \"O\"\n","      }\n","\n","  @staticmethod\n","  def getSquarePiece(piece):\n","    return OthelloGame.square_content[piece]\n","\n","  def __init__(self, n):\n","    self.n = n\n","\n","  def getInitBoard(self):\n","    # Return initial board (numpy board)\n","    b = Board(self.n)\n","    return np.array(b.pieces)\n","\n","  def getBoardSize(self):\n","    # (a,b) tuple\n","    return (self.n, self.n)\n","\n","  def getActionSize(self):\n","    # Return number of actions, n is the board size and +1 is for no-op action\n","    return self.n*self.n + 1\n","\n","  def getCanonicalForm(self, board, player):\n","    # Return state if player==1, else return -state if player==-1\n","    return player*board\n","\n","  def stringRepresentation(self, board):\n","    return board.tobytes()\n","\n","  def stringRepresentationReadable(self, board):\n","    board_s = \"\".join(self.square_content[square] for row in board for square in row)\n","    return board_s\n","\n","  def getScore(self, board, player):\n","    b = Board(self.n)\n","    b.pieces = np.copy(board)\n","    return b.countDiff(player)\n","\n","  @staticmethod\n","  def display(board):\n","    n = board.shape[0]\n","    print(\"   \", end=\"\")\n","    for y in range(n):\n","      print(y, end=\" \")\n","    print(\"\")\n","    print(\"-----------------------\")\n","    for y in range(n):\n","      print(y, \"|\", end=\"\")    # Print the row\n","      for x in range(n):\n","        piece = board[y][x]    # Get the piece to print\n","        print(OthelloGame.square_content[piece], end=\" \")\n","      print(\"|\")\n","    print(\"-----------------------\")\n","\n","  @staticmethod\n","  def displayValidMoves(moves):\n","      # Display possible moves\n","      A=np.reshape(moves[0:-1], board.shape)\n","      n = board.shape[0]\n","      print(\"  \")\n","      print(\"possible moves\")\n","      print(\"   \", end=\"\")\n","      for y in range(n):\n","        print(y, end=\" \")\n","      print(\"\")\n","      print(\"-----------------------\")\n","      for y in range(n):\n","        print(y, \"|\", end=\"\")    # Print the row\n","        for x in range(n):\n","          piece = A[y][x]    # Get the piece to print\n","          print(OthelloGame.square_content[piece], end=\" \")\n","        print(\"|\")\n","      print(\"-----------------------\")\n","\n","  def getNextState(self, board, player, action):\n","    \"\"\"\n","    Helper function to make valid move\n","    If player takes action on board, return next (board,player)\n","    and action must be a valid move\n","\n","    Args:\n","      board: np.ndarray\n","        Board of size n x n [6x6 in this case]\n","      player: Integer\n","        ID of current player\n","      action: np.ndarray\n","        Space of actions\n","\n","    Returns:\n","      (board,player) tuple signifying next state\n","    \"\"\"\n","    if action == self.n*self.n:\n","      return (board, -player)\n","    b = Board(self.n)\n","    b.pieces = np.copy(board)\n","    move = (int(action/self.n), action%self.n)\n","    b.execute_move(move, player)\n","    return (b.pieces, -player)\n","\n","  def getValidMoves(self, board, player):\n","    \"\"\"\n","    Helper function to make valid move\n","    If player takes action on board, return next (board,player)\n","    and action must be a valid move\n","\n","    Args:\n","      board: np.ndarray\n","        Board of size n x n [6x6 in this case]\n","      player: Integer\n","        ID of current player\n","      action: np.ndarray\n","        Space of action\n","\n","    Returns:\n","      valids: np.ndarray\n","        Returns a fixed size binary vector\n","    \"\"\"\n","    valids = [0]*self.getActionSize()\n","    b = Board(self.n)\n","    b.pieces = np.copy(board)\n","    legalMoves =  b.get_legal_moves(player)\n","    if len(legalMoves)==0:\n","      valids[-1]=1\n","      return np.array(valids)\n","    for x, y in legalMoves:\n","      valids[self.n*x+y]=1\n","    return np.array(valids)\n","\n","  def getGameEnded(self, board, player):\n","    \"\"\"\n","    Helper function to signify if game has ended\n","\n","    Args:\n","      board: np.ndarray\n","        Board of size n x n [6x6 in this case]\n","      player: Integer\n","        ID of current player\n","\n","    Returns:\n","      0 if not ended, 1 if player 1 won, -1 if player 1 lost\n","    \"\"\"\n","    b = Board(self.n)\n","    b.pieces = np.copy(board)\n","    if b.has_legal_moves(player):\n","      return 0\n","    if b.has_legal_moves(-player):\n","      return 0\n","    if b.countDiff(player) > 0:\n","      return 1\n","    return -1\n","\n","  def getSymmetries(self, board, pi):\n","    \"\"\"\n","    Get mirror/rotational configurations of board\n","\n","    Args:\n","      board: np.ndarray\n","        Board of size n x n [6x6 in this case]\n","      pi: np.ndarray\n","        Dimension of board\n","\n","    Returns:\n","      l: list\n","        90 degree of board, 90 degree of pi_board\n","    \"\"\"\n","    assert(len(pi) == self.n**2+1)  # 1 for pass\n","    pi_board = np.reshape(pi[:-1], (self.n, self.n))\n","    l = []\n","\n","    for i in range(1, 5):\n","      for j in [True, False]:\n","        newB = np.rot90(board, i)\n","        newPi = np.rot90(pi_board, i)\n","        if j:\n","          newB = np.fliplr(newB)\n","          newPi = np.fliplr(newPi)\n","        l += [(newB, list(newPi.ravel()) + [pi[-1]])]\n","    return l"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"swNP4ElDLv7O"},"source":["Below, we initialize and view a board."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"1ema6lrTLv7Q"},"outputs":[],"source":["# Display the board\n","set_seed(seed=SEED)\n","\n","# Set up the game\n","game = OthelloGame(6)\n","\n","# Get the initial board\n","board = game.getInitBoard()\n","\n","# Display the board\n","game.display(board)\n","\n","# Observe the game board size\n","print(f'Board size = {game.getBoardSize()}')\n","\n","# Observe the action size\n","print(f'Action size = {game.getActionSize()}')"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"suKkXcXbLv7S"},"source":["Now let's look at the valid actions for player 1 (the circles). `game.getValidMoves` returns 1s and 0s for every position on the board, 1 indicates if it is a valid place to put a new disc. Note that it turns a list (this could be reshaped into the board shape).\n","\n","We also have a method to visualize the valid actions. Compare the valid actions to the board above."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"McyKzlk6Lv7S"},"outputs":[],"source":["# Get valid moves\n","valids = game.getValidMoves(board, 1)\n","print(valids)\n","\n","# Visualize the moves\n","game.displayValidMoves(valids)"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"6eZa67s9Lv7T"},"source":["## Section 1.2: Create a random player"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"I5PRoF8pLv7T"},"source":["Let's start by setting up the game loop using a random player to start with so that we we can test the game loop and make sure it works correctly.\n","\n","To do so, we will first implement a random player in 3 steps:\n","1. determine which moves are possible at all\n","2. assign a uniform probability to each more (remember, this is a random player): 1/N for N valid moves\n","3. randomly choose a move from the possible moves"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"NJ3q5ERJLv7T"},"source":["### Coding Exercise 1.2: Implement a random player"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"BWNuCpPGLv7U"},"outputs":[],"source":["class RandomPlayer():\n","  \"\"\"\n","  Simulates Random Player\n","  \"\"\"\n","\n","  def __init__(self, game):\n","    self.game = game\n","\n","  def play(self, board):\n","    \"\"\"\n","    Simulates game play\n","\n","    Args:\n","      board: np.ndarray\n","        Board of size n x n [6x6 in this case]\n","\n","    Returns:\n","      a: int\n","        Randomly chosen move\n","    \"\"\"\n","    #################################################\n","    ## TODO for students: ##\n","    ## 1. Please compute the valid moves using getValidMoves() and the game class self.game. ##\n","    ## 2. Compute the probability over actions.##\n","    ## 3. Pick a random action based on the probability computed above.##\n","    # Fill out function and remove ##\n","    raise NotImplementedError(\"Implement the random player\")\n","    #################################################\n","\n","    # Compute the valid moves using getValidMoves()\n","    valids = self.game.getValidMoves(board, 1)\n","\n","    # Compute the probability of each move being played (random player means this should\n","    # be uniform for valid moves, 0 for others)\n","    prob = ...\n","\n","    # Pick a random action based on the probabilities (hint: np.choice is useful)\n","    a = ...\n","\n","    return a\n","\n","\n","# Add event to airtable\n","atform.add_event('Coding Exercise 1.2: Implement a random player')"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"RdzLD4q-Lv7U"},"source":["[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D5_ReinforcementLearningForGames/solutions/W3D5_Tutorial1_Solution_8fbd97fa.py)\n","\n"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"e_iBEbw3Lv7V"},"source":["## Section 1.3: Create two random agents to play against each other\n","\n","Now we create 2 random players and let them play against one another for a number of times... We will use some nice functionality we imported above, including the `Arena` class that allows multiple game plays. You can check out the code here if you want, but it is not necessary: https://github.com/raymondchua/nma_rl_games\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"zvkuo8FMLv7V"},"outputs":[],"source":["# Define the random player\n","player1 = RandomPlayer(game).play  # Player 1 is a random player\n","player2 = RandomPlayer(game).play  # Player 2 is a random player\n","\n","# Define number of games\n","num_games = 20\n","\n","# Start the competition\n","set_seed(seed=SEED)\n","arena = Arena.Arena(player1, player2 , game, display=None)  # To see the steps of the competition set \"display=OthelloGame.display\"\n","result = arena.playGames(num_games, verbose=False)  # return  ( number of games won by player1, num of games won by player2, num of games won by nobody)\n","print(f\"\\n\\n{result}\")"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"x_BRcGkzLv7W"},"source":["```\n","(11, 9, 0)\n","```"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"TuwYVkadLv7W"},"source":["The results are displayed in the following way: (Number of player 1 wins, number of player 2 wins, number of ties)"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"Gaq_v7WkLv7W"},"source":["## Section 1.4: Compute win rate for the random player (player 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{},"id":"KzfJUSLpLv7X"},"outputs":[],"source":["print(f\"Number of games won by player1 = {result[0]}, \"\n","      f\"Number of games won by player2 = {result[1]} out of {num_games} games\")\n","win_rate_player1 = result[0]/num_games\n","print(f\"\\nWin rate for player1 over 20 games: {round(win_rate_player1*100, 1)}%\")"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"LQZDHuvSLv7X"},"source":["```\n","Number of games won by player1 = 11, Number of games won by player2 = 9 out of 20 games\n","\n","Win rate for player1 over 20 games: 55.0%\n","```"]},{"cell_type":"markdown","metadata":{"execution":{},"id":"YSoNkwlxLv7X"},"source":["**Note**: the random player is purely policy-based. It contains no estimates of value. Next we'll see how to estimate and use value functions for game playing."]},{"cell_type":"markdown","metadata":{"execution":{},"id":"PRWZZ8l2Lv7Y"},"source":["---\n","# Summary\n","\n","In this tutorial, you have learned about the Othello game, how to implement a game loop, and create a random player. "]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{},"id":"AZY9-dqMLv7Y"},"outputs":[],"source":["# @title Airtable Submission Link\n","from IPython import display as IPyDisplay\n","IPyDisplay.HTML(\n","    f\"\"\"\n","  <div>\n","    <a href= \"{atform.url()}\" target=\"_blank\">\n","    <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1\"\n","  alt=\"button link to Airtable\" style=\"width:410px\"></a>\n","    </div>\"\"\" )"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Cópia de W3D5_Tutorial1","provenance":[{"file_id":"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial1.ipynb","timestamp":1659118759628}],"toc_visible":true},"kernel":{"display_name":"Python 3","language":"python","name":"python3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}